{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "## many to one RNN\n",
    "\n",
    "class RNN:\n",
    "\n",
    "  def __init__(self, layerDim, activations, a0):\n",
    "    self.a0 = a0\n",
    "    self.acacheNN = []\n",
    "    self.zcacheNN = []\n",
    "    self.acacheRNN = []\n",
    "    self.zcacheRNN = []\n",
    "\n",
    "    self.layerDim = layerDim\n",
    "    self.layers = len(layerDim)\n",
    "    self.activations = activations\n",
    "    self.t = 0\n",
    "\n",
    "    self.W = []\n",
    "    self.b = []\n",
    "    self.dW = []\n",
    "    self.db = []\n",
    "\n",
    "    self.init_weights()\n",
    "\n",
    "  def init_weights(self):\n",
    "    self.W = []\n",
    "    self.b = []\n",
    "    for i in range(2, self.layers-1):\n",
    "      # print(i)\n",
    "      # print(self.layerDim[i])\n",
    "      # print(self.layerDim[i-1])\n",
    "      self.W.append(np.random.randn(self.layerDim[i], self.layerDim[i-1]) * np.sqrt(2/self.layerDim[i-1]))\n",
    "      self.b.append(np.zeros((self.layerDim[i], 1)))\n",
    "\n",
    "      self.dW.append(np.zeros((self.layerDim[i], self.layerDim[i-1])))\n",
    "      self.db.append(np.zeros((self.layerDim[i], 1)))\n",
    "\n",
    "    self.Wx = np.random.randn(self.layerDim[1], self.layerDim[0]) * np.sqrt(2/self.layerDim[0])\n",
    "    self.Wa = np.random.randn(self.layerDim[1], self.layerDim[-2]) * np.sqrt(2/self.layerDim[1])\n",
    "    self.ba = np.zeros((self.layerDim[1], 1))\n",
    "\n",
    "    self.dWx = np.zeros((self.layerDim[1], self.layerDim[0]))\n",
    "    self.dWa = np.zeros((self.layerDim[1], self.layerDim[-2]))\n",
    "    self.dba = np.zeros((self.layerDim[1], 1))\n",
    "\n",
    "    self.Wy = np.random.randn(self.layerDim[-1], self.layerDim[-2]) * np.sqrt(2/self.layerDim[-2])\n",
    "    self.by = np.zeros((self.layerDim[-1], 1))\n",
    "\n",
    "    self.dWy = np.zeros((self.layerDim[-1], self.layerDim[-2]))\n",
    "    self.dby = np.zeros((self.layerDim[-1], 1))\n",
    "\n",
    "\n",
    "  def sigmoid (self, Z):\n",
    "    Z = np.clip(Z, -500, 500) \n",
    "    return 1/(1+np.exp(-Z))\n",
    "  \n",
    "  def relu (self, Z):\n",
    "    return np.maximum(0, Z)\n",
    "  \n",
    "  def tanh (self, Z):\n",
    "    return np.tanh(Z)\n",
    "  \n",
    "  def softmax (self, Z):\n",
    "    expZ = np.exp(Z - np.max(Z))\n",
    "    return expZ / expZ.sum(axis=0, keepdims=True)\n",
    "  \n",
    "  def activationsfunc (self, Z, activation):\n",
    "    if activation == 'sigmoid':\n",
    "      return self.sigmoid(Z)\n",
    "    elif activation == 'relu':\n",
    "      return self.relu(Z)\n",
    "    elif activation == 'tanh':\n",
    "      return self.tanh(Z)\n",
    "    else:\n",
    "      return Z\n",
    "    \n",
    "  def activationsDerivative(self, Z, activation):\n",
    "    if activation == 'sigmoid':\n",
    "      sig = self.sigmoid(Z)\n",
    "      return sig * (1 - sig)\n",
    "    elif activation == 'relu':\n",
    "      return (Z > 0).astype(Z.dtype)\n",
    "    elif activation == 'tanh':\n",
    "      return 1 - np.power(self.tanh(Z), 2)\n",
    "    else:\n",
    "      return 1\n",
    "    \n",
    "  def singleForwardNN(self, a_prev, w, b, activation):\n",
    "    z = w @ a_prev + b\n",
    "    a = self.activationsfunc(z, activation)\n",
    "\n",
    "    self.acacheNN[self.t].append(a)\n",
    "    self.zcacheNN[self.t].append(z)\n",
    "\n",
    "    return a\n",
    "  \n",
    "  def forwardNN(self, X):\n",
    "    self.acacheNN.append([X])\n",
    "    self.zcacheNN.append([])\n",
    "\n",
    "    a = X\n",
    "    for i in range(len(self.W)):\n",
    "      a = self.singleForwardNN(a, self.W[i], self.b[i], self.activations[i+1])\n",
    "\n",
    "    return a\n",
    "  \n",
    "  def singleForwardRNN(self, a_prev, x, activation):\n",
    "    # print(x.shape)\n",
    "    # print(a_prev.shape)\n",
    "    # print(self.Wx.shape)\n",
    "    # print(self.Wa.shape)\n",
    "    # print(self.ba.shape)\n",
    "    z = self.Wx @ x + self.Wa @ a_prev + self.ba\n",
    "    a = self.activationsfunc(z, activation)\n",
    "\n",
    "    self.acacheRNN.append(a)\n",
    "    self.zcacheRNN.append(z)\n",
    "\n",
    "    a = self.forwardNN(a)\n",
    "\n",
    "    return a\n",
    "  \n",
    "  def forwardRNN(self, X):\n",
    "    a = self.a0\n",
    "    self.acacheRNN = [a]\n",
    "    self.zcacheRNN = []\n",
    "    self.acacheNN = []\n",
    "    self.zcacheNN = []\n",
    "    self.t = 0\n",
    "\n",
    "    for i in range(X.shape[1]):\n",
    "      a = self.singleForwardRNN(a, X[:, i:i+1], self.activations[0])\n",
    "      self.t += 1\n",
    "    \n",
    "    return a\n",
    "  \n",
    "  def singleBackwardNN(self, da, w, b, z, a_prev, activation):\n",
    "    dz = da * self.activationsDerivative(z, activation)\n",
    "    dw = dz @ a_prev.T\n",
    "    db = np.sum(dz, axis=1, keepdims=True)\n",
    "    da_prev = w.T @ dz\n",
    "\n",
    "    return da_prev, dw, db\n",
    "  \n",
    "  def backwardNN(self, da):\n",
    "\n",
    "    for i in range(len(self.W)-1, -1, -1):\n",
    "      da, dw, db = self.singleBackwardNN(da, self.W[i], self.b[i], self.zcacheNN[self.t][i], self.acacheNN[self.t][i], self.activations[i+1])\n",
    "      self.dW[i] += dw\n",
    "      self.db[i] += db\n",
    "\n",
    "    return da\n",
    "  \n",
    "  def singleBackwardRNN(self, da,z, x, a_prev, activation):\n",
    "    da = self.backwardNN(da)\n",
    "\n",
    "    dz = da * self.activationsDerivative(z, activation)\n",
    "    self.dWx += dz @ x.T\n",
    "    self.dWa += dz @ a_prev.T\n",
    "    self.dba += np.sum(dz, axis=1, keepdims=True)\n",
    "\n",
    "    da_prev = self.Wa.T @ dz\n",
    "\n",
    "    return da_prev\n",
    "  \n",
    "  def backwardRNN(self, lossDerivative, X):\n",
    "    dz = lossDerivative\n",
    "    # print(dz.shape)\n",
    "    # print(self.acacheRNN[-1].shape)\n",
    "    # print(self.dWy.shape)\n",
    "    self.dWy += dz @ self.acacheNN[-1][-1].T\n",
    "    self.dby += np.sum(dz, axis=1, keepdims=True)\n",
    "    da = self.Wy.T @ dz\n",
    "\n",
    "\n",
    "    for i in range(X.shape[1]-1, -1, -1):\n",
    "      self.t -= 1\n",
    "      da = self.singleBackwardRNN(da, self.zcacheRNN[i], X[:, i:i+1], self.acacheNN[self.t][-1], self.activations[0])\n",
    "\n",
    "    return da\n",
    "  \n",
    "  def updateWeights(self, learning_rate):\n",
    "    for i in range(len(self.W)):\n",
    "      self.W[i] -= learning_rate * self.dW[i]\n",
    "      self.b[i] -= learning_rate * self.db[i]\n",
    "\n",
    "      self.dW[i] = np.zeros(self.dW[i].shape)\n",
    "      self.db[i] = np.zeros(self.db[i].shape)\n",
    "      \n",
    "    self.Wx -= learning_rate * self.dWx\n",
    "    self.Wa -= learning_rate * self.dWa\n",
    "    self.ba -= learning_rate * self.dba\n",
    "\n",
    "    self.Wy -= learning_rate * self.dWy\n",
    "    self.by -= learning_rate * self.dby\n",
    "\n",
    "    self.dWx = np.zeros(self.dWx.shape)\n",
    "    self.dWa = np.zeros(self.dWa.shape)\n",
    "    self.dba = np.zeros(self.dba.shape)\n",
    "    self.dWy = np.zeros(self.dWy.shape)\n",
    "    self.dby = np.zeros(self.dby.shape)\n",
    "    self.dWx = np.zeros(self.dWx.shape)\n",
    "\n",
    "  \n",
    "  def predict(self, X):\n",
    "    a = self.forwardRNN(X)\n",
    "    y = self.Wy @ a + self.by\n",
    "    y = self.softmax(y)\n",
    "\n",
    "    return y.reshape(-1, 1)\n",
    "  \n",
    "  def loss(self, y, y_hat):\n",
    "    y = np.clip(y, 1e-10, 1-1e-10)\n",
    "    y_hat = np.clip(y_hat, 1e-10, 1-1e-10)\n",
    "\n",
    "    return -np.sum(y * np.log(y_hat))\n",
    "  \n",
    "  def lossDerivativeSoftmax(self, y, y_hat):\n",
    "    return  y_hat - y\n",
    "  \n",
    "  def train(self, X, Y, learning_rate, epochs):\n",
    "    examples = len(X)\n",
    "\n",
    "    for i in range(epochs):\n",
    "      loss = 0\n",
    "      for j in range(examples):\n",
    "        y_hat = self.predict(X[j])\n",
    "        loss += self.loss(Y[0,j:j+1], y_hat)\n",
    "        lossDerivative = self.lossDerivativeSoftmax(Y[0,j:j+1], y_hat)\n",
    "        self.backwardRNN(lossDerivative, X[j])\n",
    "      self.updateWeights(learning_rate)\n",
    "      \n",
    "      if i % 100 == 0:\n",
    "        print(\"Epoch: \", i, \" Loss: \", loss)\n",
    "      \n",
    "      # print(\"Epoch: \", i, \" Loss: \", loss)\n",
    "\n",
    "  def accuracy (self, X, Y):\n",
    "    # A = self.predict(X)\n",
    "    A = np.zeros(Y.shape)\n",
    "    for i in range(Y.shape[1]):\n",
    "      A[:, i:i+1] = self.predict(X[i])\n",
    "    return np.mean(np.argmax(Y, axis=0) == np.argmax(A, axis=0))\n",
    "\n",
    "  def precision (self, X, Y):\n",
    "    A = np.zeros(Y.shape)\n",
    "    for i in range(Y.shape[1]):\n",
    "      A[:, i:i+1] = self.predict(X[i])\n",
    "\n",
    "    A = (A == A.max(axis=0, keepdims=1)).astype(int)\n",
    "    true_positive = np.sum((Y == 1) & (A == 1))\n",
    "    predicted_positive = np.sum(A == 1)\n",
    "    return true_positive / predicted_positive if predicted_positive > 0 else 0\n",
    "    \n",
    "  def saveWeights(self, filename):\n",
    "    np.savez(filename, W=self.W, b=self.b, Wx=self.Wx, Wa=self.Wa, ba=self.ba, Wy=self.Wy, by=self.by)\n",
    "\n",
    "  def loadWeights(self, filename):\n",
    "    data = np.load(filename)\n",
    "    self.W = data['W']\n",
    "    self.b = data['b']\n",
    "    self.Wx = data['Wx']\n",
    "    self.Wa = data['Wa']\n",
    "    self.ba = data['ba']\n",
    "    self.Wy = data['Wy']\n",
    "    self.by = data['by']\n",
    "\n",
    "  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define a function to load GloVe vectors\n",
    "def load_glove_vectors(filepath):\n",
    "    word_to_vec = {}\n",
    "    with open(filepath, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            vector = np.asarray(values[1:], dtype='float32')\n",
    "            word_to_vec[word] = vector\n",
    "\n",
    "    word_to_vec['<eol>'] = np.zeros((100,))\n",
    "    word_to_vec['<unk>'] = np.zeros((100,))\n",
    "    return word_to_vec\n",
    "\n",
    "# Load the vectors\n",
    "glove_vectors = load_glove_vectors('Data/glove.6B/glove.6B.100d.txt')\n",
    "\n",
    "# glove_vectors[\"don't\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>Text</th>\n",
       "      <th>Spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[date, wed, number, aug, number, number, numbe...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>[martin, a, posted, tassos, papadopoulos, the,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>[man, threatens, explosion, in, moscow, thursd...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>[klez, the, virus, that, won, t, die, already,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>[in, adding, cream, to, spaghetti, carbonara, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>1</td>\n",
       "      <td>[abc, s, good, morning, america, ranks, it, th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>1</td>\n",
       "      <td>[hyperlink, hyperlink, hyperlink, let, mortgag...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>1</td>\n",
       "      <td>[thank, you, for, shopping, with, us, gifts, f...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>1</td>\n",
       "      <td>[the, famous, ebay, marketing, e, course, lear...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>1</td>\n",
       "      <td>[hello, this, is, chinese, traditional, 子, 件, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                               Text  Spam\n",
       "0         0  [date, wed, number, aug, number, number, numbe...     0\n",
       "1         0  [martin, a, posted, tassos, papadopoulos, the,...     0\n",
       "2         0  [man, threatens, explosion, in, moscow, thursd...     0\n",
       "3         0  [klez, the, virus, that, won, t, die, already,...     0\n",
       "4         0  [in, adding, cream, to, spaghetti, carbonara, ...     0\n",
       "...     ...                                                ...   ...\n",
       "2995      1  [abc, s, good, morning, america, ranks, it, th...     1\n",
       "2996      1  [hyperlink, hyperlink, hyperlink, let, mortgag...     1\n",
       "2997      1  [thank, you, for, shopping, with, us, gifts, f...     1\n",
       "2998      1  [the, famous, ebay, marketing, e, course, lear...     1\n",
       "2999      1  [hello, this, is, chinese, traditional, 子, 件, ...     1\n",
       "\n",
       "[3000 rows x 3 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    return re.sub(r'[^\\w\\s]', '', str(text).strip())\n",
    "\n",
    "def remove_extra_spaces(text):\n",
    "    return re.sub(' +', ' ', text)\n",
    "\n",
    "df = pd.read_csv('Data/spam_or_not_spam/spam_or_not_spam.csv')\n",
    "# df['Text'] = df['Message'] if not NaN else df['Subject']\n",
    "\n",
    "# df['Text'] = df['Message'].fillna(df['Subject'])\n",
    "\n",
    "# df = df.drop(columns=['Message', 'Subject', 'Message ID', 'Date'], axis=1)\n",
    "\n",
    "df[\"Text\"] = df[\"email\"].apply(remove_punctuation)\n",
    "df[\"Text\"] = df[\"Text\"].str.replace('\\n', ' ')\n",
    "df[\"Text\"] = df[\"Text\"].apply(remove_extra_spaces)\n",
    "df[\"Text\"] = df[\"Text\"].str.strip()\n",
    "df[\"Text\"] = df[\"Text\"].str.lower()\n",
    "df[\"Text\"] = df[\"Text\"].str.split(' ')\n",
    "\n",
    "df = df.drop(columns=['email'], axis=1)\n",
    "\n",
    "df['Spam'] = df['label']\n",
    "# df[\"Spam/Ham\"] = df[\"Spam/Ham\"].map({'spam': 1, 'ham': 0})\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['Text'].values\n",
    "Y = df['Spam'].values\n",
    "\n",
    "X_vec = []\n",
    "Y_vec = np.zeros((2, len(Y)))\n",
    "\n",
    "for i in range(len(X)):\n",
    "  vec = np.zeros((100, len(X[i])))\n",
    "  for j in range(len(X[i])):\n",
    "    if X[i][j] in glove_vectors:\n",
    "      vec[:, j] = glove_vectors[X[i][j]]\n",
    "    else:\n",
    "      vec[:, j] = glove_vectors['<unk>']\n",
    "\n",
    "  X_vec.append(vec)\n",
    "  Y_vec[Y[i] - 1, i] = 1\n",
    "\n",
    "random = np.random.permutation(len(X_vec))\n",
    "theshold = int(0.8*len(random))\n",
    "X_train = [X_vec[i] for i in random[0:theshold]]\n",
    "Y_train = Y_vec[:, random[0:theshold]]\n",
    "\n",
    "X_test = [X_vec[i] for i in random[theshold:]]\n",
    "Y_test = Y_vec[:, random[theshold:]]\n",
    "# print(X_vec[0])\n",
    "# print(Y_vec[:, 0:1])\n",
    "# Y_vec[:, 0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNN([100, 100, 50, 2], ['tanh', 'tanh', 'softmax'], np.zeros((50, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.loadWeights('RnnModelTest1.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.7525\n",
      "Test accuracy: 0.7516666666666667\n",
      "Train precision: 0.7525\n",
      "Test precision: 0.7516666666666667\n"
     ]
    }
   ],
   "source": [
    "print(\"Train accuracy:\", model.accuracy(X_train, Y_train))\n",
    "print(\"Test accuracy:\", model.accuracy(X_test, Y_test))\n",
    "\n",
    "print(\"Train precision:\", model.precision(X_train, Y_train))\n",
    "print(\"Test precision:\", model.precision(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.49964397]\n",
      " [0.50035603]]\n",
      "[[0.]\n",
      " [1.]]\n"
     ]
    }
   ],
   "source": [
    "print(model.predict(X_train[1]))\n",
    "print(Y_train[:, 0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
