{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81807083",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-09-01T07:37:27.920758Z",
     "iopub.status.busy": "2024-09-01T07:37:27.920421Z",
     "iopub.status.idle": "2024-09-01T07:37:28.665214Z",
     "shell.execute_reply": "2024-09-01T07:37:28.664154Z"
    },
    "papermill": {
     "duration": 0.753907,
     "end_time": "2024-09-01T07:37:28.667320",
     "exception": false,
     "start_time": "2024-09-01T07:37:27.913413",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/emaillstm/pytorch/default/1/modelCombined1.pth\n",
      "/kaggle/input/email-classification-dataset/glove.6B.200d.txt\n",
      "/kaggle/input/email-classification-dataset/glove.6B.50d.txt\n",
      "/kaggle/input/email-classification-dataset/glove.6B.300d.txt\n",
      "/kaggle/input/email-classification-dataset/combined_data.csv\n",
      "/kaggle/input/email-classification-dataset/glove.6B.100d.txt\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d77bda7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-01T07:37:28.679700Z",
     "iopub.status.busy": "2024-09-01T07:37:28.679272Z",
     "iopub.status.idle": "2024-09-01T07:37:28.683806Z",
     "shell.execute_reply": "2024-09-01T07:37:28.682966Z"
    },
    "papermill": {
     "duration": 0.012524,
     "end_time": "2024-09-01T07:37:28.685605",
     "exception": false,
     "start_time": "2024-09-01T07:37:28.673081",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import re\n",
    "\n",
    "# def remove_punctuation(text):\n",
    "#     return re.sub(r'[^\\w\\s]', '', str(text).strip())\n",
    "\n",
    "# def remove_extra_spaces(text):\n",
    "#     return re.sub(' +', ' ', text)\n",
    "\n",
    "# df = pd.read_csv('/kaggle/input/spamnotspamkaggle/spam_or_not_spam.csv')\n",
    "# # df['Text'] = df['Message'] if not NaN else df['Subject']\n",
    "\n",
    "# # df['Text'] = df['Message'].fillna(df['Subject'])\n",
    "\n",
    "# # df = df.drop(columns=['Message', 'Subject', 'Message ID', 'Date'], axis=1)\n",
    "\n",
    "# df[\"Text\"] = df[\"email\"].apply(remove_punctuation)\n",
    "# df[\"Text\"] = df[\"Text\"].str.replace('\\n', ' ')\n",
    "# df[\"Text\"] = df[\"Text\"].apply(remove_extra_spaces)\n",
    "# df[\"Text\"] = df[\"Text\"].str.strip()\n",
    "# df[\"Text\"] = df[\"Text\"].str.lower()\n",
    "# df[\"Text\"] = df[\"Text\"].str.split(' ')\n",
    "\n",
    "# df = df.drop(columns=['email'], axis=1)\n",
    "\n",
    "# df['Spam'] = df['label']\n",
    "# # df[\"Spam/Ham\"] = df[\"Spam/Ham\"].map({'spam': 1, 'ham': 0})\n",
    "\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5a66179",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-01T07:37:28.697118Z",
     "iopub.status.busy": "2024-09-01T07:37:28.696850Z",
     "iopub.status.idle": "2024-09-01T07:37:47.586970Z",
     "shell.execute_reply": "2024-09-01T07:37:47.585991Z"
    },
    "papermill": {
     "duration": 18.898235,
     "end_time": "2024-09-01T07:37:47.589054",
     "exception": false,
     "start_time": "2024-09-01T07:37:28.690819",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[ounce, feather, bowl, hummingbird, opec, mome...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[wulvob, get, your, medircations, online, qnb,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[computer, connection, from, cnn, com, wednesd...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[university, degree, obtain, a, prosperous, fu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[thanks, for, all, your, answers, guys, i, kno...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83443</th>\n",
       "      <td>[hi, given, a, date, how, do, i, get, the, las...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83444</th>\n",
       "      <td>[now, you, can, order, software, on, cd, or, d...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83445</th>\n",
       "      <td>[dear, valued, member, canadianpharmacy, provi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83446</th>\n",
       "      <td>[subscribe, change, profile, contact, us, long...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83447</th>\n",
       "      <td>[get, the, most, out, of, life, viagra, has, h...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>83448 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text  Spam\n",
       "0      [ounce, feather, bowl, hummingbird, opec, mome...     1\n",
       "1      [wulvob, get, your, medircations, online, qnb,...     1\n",
       "2      [computer, connection, from, cnn, com, wednesd...     0\n",
       "3      [university, degree, obtain, a, prosperous, fu...     1\n",
       "4      [thanks, for, all, your, answers, guys, i, kno...     0\n",
       "...                                                  ...   ...\n",
       "83443  [hi, given, a, date, how, do, i, get, the, las...     0\n",
       "83444  [now, you, can, order, software, on, cd, or, d...     1\n",
       "83445  [dear, valued, member, canadianpharmacy, provi...     1\n",
       "83446  [subscribe, change, profile, contact, us, long...     0\n",
       "83447  [get, the, most, out, of, life, viagra, has, h...     1\n",
       "\n",
       "[83448 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "df = pd.read_csv('/kaggle/input/email-classification-dataset/combined_data.csv')\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    return re.sub(r'[^\\w\\s]', '', str(text).strip())\n",
    "\n",
    "def remove_extra_spaces(text):\n",
    "    return re.sub(' +', ' ', text)\n",
    "\n",
    "# df = pd.read_csv('Data/spam_or_not_spam/spam_or_not_spam.csv')\n",
    "# df['Text'] = df['Message'] if not NaN else df['Subject']\n",
    "\n",
    "# df['Text'] = df['Message'].fillna(df['Subject'])\n",
    "\n",
    "# df = df.drop(columns=['Message', 'Subject', 'Message ID', 'Date'], axis=1)\n",
    "\n",
    "df[\"Text\"] = df[\"text\"].apply(remove_punctuation)\n",
    "df[\"Text\"] = df[\"Text\"].str.replace('\\n', ' ')\n",
    "df[\"Text\"] = df[\"Text\"].apply(remove_extra_spaces)\n",
    "df[\"Text\"] = df[\"Text\"].str.strip()\n",
    "df[\"Text\"] = df[\"Text\"].str.lower()\n",
    "df[\"Text\"] = df[\"Text\"].str.split(' ')\n",
    "\n",
    "df['Spam'] = df['label']\n",
    "\n",
    "df = df.drop(columns=['text', 'label'], axis=1)\n",
    "# df[\"Spam/Ham\"] = df[\"Spam/Ham\"].map({'spam': 1, 'ham': 0})\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b5887f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-01T07:37:47.602186Z",
     "iopub.status.busy": "2024-09-01T07:37:47.601899Z",
     "iopub.status.idle": "2024-09-01T07:38:03.545144Z",
     "shell.execute_reply": "2024-09-01T07:38:03.544094Z"
    },
    "papermill": {
     "duration": 15.952766,
     "end_time": "2024-09-01T07:38:03.547664",
     "exception": false,
     "start_time": "2024-09-01T07:37:47.594898",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.utils.rnn as rnn_utils\n",
    "\n",
    "# Define a function to load GloVe vectors\n",
    "def load_glove_vectors(filepath):\n",
    "    word_to_vec = {}\n",
    "    with open(filepath, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            vector = np.asarray(values[1:], dtype='float32')\n",
    "            word_to_vec[word] = vector\n",
    "\n",
    "    word_to_vec['<eol>'] = np.zeros((100,))\n",
    "    word_to_vec['<unk>'] = np.zeros((100,))\n",
    "    return word_to_vec\n",
    "\n",
    "# Load the vectors\n",
    "glove_vectors = load_glove_vectors('/kaggle/input/email-classification-dataset/glove.6B.100d.txt')\n",
    "\n",
    "# glove_vectors[\"don't\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6617c7e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-01T07:38:03.561075Z",
     "iopub.status.busy": "2024-09-01T07:38:03.560601Z",
     "iopub.status.idle": "2024-09-01T07:38:51.633633Z",
     "shell.execute_reply": "2024-09-01T07:38:51.632581Z"
    },
    "papermill": {
     "duration": 48.08226,
     "end_time": "2024-09-01T07:38:51.636146",
     "exception": false,
     "start_time": "2024-09-01T07:38:03.553886",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = df['Text'].values\n",
    "Y = df['Spam'].values\n",
    "\n",
    "X_vec = []\n",
    "# Y_vec = np.zeros((2, len(Y)))\n",
    "Y_vec = np.array(Y)\n",
    "\n",
    "for i in range(len(X)):\n",
    "  vec = np.zeros((100, len(X[i])))\n",
    "  for j in range(len(X[i])):\n",
    "    if X[i][j] in glove_vectors:\n",
    "      vec[:, j] = glove_vectors[X[i][j]]\n",
    "    else:\n",
    "      vec[:, j] = glove_vectors['<unk>']\n",
    "\n",
    "  X_vec.append(torch.tensor(vec.reshape(-1, 100), dtype=torch.float32))\n",
    "\n",
    "Y_vec = torch.tensor(Y_vec, dtype=torch.float32)\n",
    "#   Y_vec[Y[i] - 1, i] = 1\n",
    "\n",
    "# random = np.random.permutation(len(X_vec))\n",
    "# theshold = int(0.8*len(random))\n",
    "# X_train = [X_vec[i].reshape(-1,100) for i in random[0:theshold]]\n",
    "# Y_train = Y_vec[random[0:theshold]]\n",
    "\n",
    "# X_test = [X_vec[i].reshape(-1,100) for i in random[theshold:]]\n",
    "# Y_test = Y_vec[random[theshold:]]\n",
    "\n",
    "# Y_train = Y_train.reshape(-1, 1)\n",
    "# Y_test = Y_test.reshape(-1, 1)\n",
    "\n",
    "X_vec = X_vec\n",
    "Y_vec = Y_vec.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a9f4636",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-01T07:38:51.649721Z",
     "iopub.status.busy": "2024-09-01T07:38:51.649400Z",
     "iopub.status.idle": "2024-09-01T07:38:51.653232Z",
     "shell.execute_reply": "2024-09-01T07:38:51.652395Z"
    },
    "papermill": {
     "duration": 0.012302,
     "end_time": "2024-09-01T07:38:51.655179",
     "exception": false,
     "start_time": "2024-09-01T07:38:51.642877",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # print(\"Lengths:\", lengths)\n",
    "# print(\"Padded Sequences Shape:\", X.shape)\n",
    "\n",
    "# print(\"X_padded Device:\", X.device)\n",
    "# print(\"Lengths Device:\", lengths.device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20fbdf95",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-01T07:38:51.667697Z",
     "iopub.status.busy": "2024-09-01T07:38:51.667390Z",
     "iopub.status.idle": "2024-09-01T07:38:51.714459Z",
     "shell.execute_reply": "2024-09-01T07:38:51.713564Z"
    },
    "papermill": {
     "duration": 0.05541,
     "end_time": "2024-09-01T07:38:51.716318",
     "exception": false,
     "start_time": "2024-09-01T07:38:51.660908",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_vec[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bde21a67",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-01T07:38:51.728843Z",
     "iopub.status.busy": "2024-09-01T07:38:51.728588Z",
     "iopub.status.idle": "2024-09-01T07:38:51.733938Z",
     "shell.execute_reply": "2024-09-01T07:38:51.733129Z"
    },
    "papermill": {
     "duration": 0.013749,
     "end_time": "2024-09-01T07:38:51.735833",
     "exception": false,
     "start_time": "2024-09-01T07:38:51.722084",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 100])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_vec[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5de8a22a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-01T07:38:51.748886Z",
     "iopub.status.busy": "2024-09-01T07:38:51.748614Z",
     "iopub.status.idle": "2024-09-01T07:38:57.648696Z",
     "shell.execute_reply": "2024-09-01T07:38:57.647496Z"
    },
    "papermill": {
     "duration": 5.909225,
     "end_time": "2024-09-01T07:38:57.650879",
     "exception": false,
     "start_time": "2024-09-01T07:38:51.741654",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 100])\n",
      "5216\n"
     ]
    }
   ],
   "source": [
    "# X = torch.tensor(X, dtype=torch.float32)\n",
    "# X = [torch.tensor(x, dtype=torch.float32) for x in X_vec]\n",
    "\n",
    "X = X_vec\n",
    "Y = Y_vec\n",
    "\n",
    "print(X[0].size())\n",
    "\n",
    "# lengths = [seq.size(0) for seq in X]\n",
    "\n",
    "# print(max(lengths))\n",
    "\n",
    "# X = rnn_utils.pad_sequence(X, batch_first=True, padding_value=0)\n",
    "# Y = torch.tensor(Y_vec, dtype=torch.float32)\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "# dataset = torch.utils.data.TensorDataset(X, Y)\n",
    "dataset = [(X[i], Y[i]) for i in range(len(X))]\n",
    "dataset.sort(key = lambda x: x[0].size(0))\n",
    "\n",
    "X, Y = zip(*dataset)\n",
    "\n",
    "dataset = [(rnn_utils.pad_sequence(X[i: i + batch_size],\n",
    "                                  batch_first = True,\n",
    "                                  padding_value=0),\n",
    "               torch.stack(Y[i: i + batch_size])) for i in range(0, len(dataset), batch_size)]\n",
    "\n",
    "print(len(dataset))\n",
    "# print(dataset[0][0].size())\n",
    "# print(dataset[0][1].size())\n",
    "\n",
    "train_size = int(0.99 * len(dataset))\n",
    "# test_size = len(dataset) - train_size\n",
    "\n",
    "random = np.random.permutation(len(dataset))\n",
    "\n",
    "train_dataset = [dataset[i] for i in random[0:train_size]]\n",
    "test_dataset = [dataset[i] for i in random[train_size:]]\n",
    "\n",
    "# train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "# print(train_dataset)\n",
    "\n",
    "# train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "#                                            batch_size = batch_size,\n",
    "#                                            shuffle = True)\n",
    "\n",
    "# test_loader = torch.utils.data.DataLoader(test_dataset,\n",
    "#                                            batch_size = batch_size,\n",
    "#                                            shuffle = False)\n",
    "\n",
    "# TrainLengths = torch.tensor([[x[0].size(0)] * batch_size for x in train_loader], dtype=torch.int64)\n",
    "# TestLengths = torch.tensor([[x[0].size(0)]* batch_size for x in test_loader], dtype=torch.int64)\n",
    "\n",
    "# print(max(TrainLengths[:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c10a408f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-01T07:38:57.664885Z",
     "iopub.status.busy": "2024-09-01T07:38:57.664575Z",
     "iopub.status.idle": "2024-09-01T07:38:57.669570Z",
     "shell.execute_reply": "2024-09-01T07:38:57.668682Z"
    },
    "papermill": {
     "duration": 0.014258,
     "end_time": "2024-09-01T07:38:57.671570",
     "exception": false,
     "start_time": "2024-09-01T07:38:57.657312",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 55, 100])\n",
      "torch.Size([16, 1])\n"
     ]
    }
   ],
   "source": [
    "print(dataset[1000][0].size())\n",
    "print(dataset[1000][1].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "18362901",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-01T07:38:57.684649Z",
     "iopub.status.busy": "2024-09-01T07:38:57.684361Z",
     "iopub.status.idle": "2024-09-01T07:38:57.690652Z",
     "shell.execute_reply": "2024-09-01T07:38:57.689758Z"
    },
    "papermill": {
     "duration": 0.014858,
     "end_time": "2024-09-01T07:38:57.692459",
     "exception": false,
     "start_time": "2024-09-01T07:38:57.677601",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calLenghts(data):\n",
    "    \n",
    "    device = data.device\n",
    "    batch_size = data.size(0)\n",
    "    sequence_length = data.size(1)\n",
    "    \n",
    "    lengths = torch.ones(batch_size, dtype = torch.int64)\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        \n",
    "        seq = data[i]\n",
    "        \n",
    "        non_zero_index = (seq != 0).any(dim=1).nonzero(as_tuple=True)[0]\n",
    "        \n",
    "        if len(non_zero_index) > 0:\n",
    "            lengths[i] = non_zero_index[-1] + 1\n",
    "        \n",
    "    lengths = lengths.to('cpu')\n",
    "    return lengths\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a770ce0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-01T07:38:57.705397Z",
     "iopub.status.busy": "2024-09-01T07:38:57.705150Z",
     "iopub.status.idle": "2024-09-01T07:38:57.767209Z",
     "shell.execute_reply": "2024-09-01T07:38:57.766339Z"
    },
    "papermill": {
     "duration": 0.070662,
     "end_time": "2024-09-01T07:38:57.769121",
     "exception": false,
     "start_time": "2024-09-01T07:38:57.698459",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# device = torch'cpu'\n",
    "\n",
    "# lengths = torch.tensor(lengths, dtype=torch.long)\n",
    "# lengths = lengths.cpu()\n",
    "# lengths = lengths.to(torch.int64)\n",
    "\n",
    "# TrainLengths = TrainLengths.to('cpu')\n",
    "# TestLengths = TestLengths.to('cpu')\n",
    "\n",
    "# print(\"TestLenghts\", TestLengths.shape)\n",
    "# print(\"TrainLengths\", TrainLengths.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a0101ff7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-01T07:38:57.782447Z",
     "iopub.status.busy": "2024-09-01T07:38:57.782186Z",
     "iopub.status.idle": "2024-09-01T14:20:45.787546Z",
     "shell.execute_reply": "2024-09-01T14:20:45.786509Z"
    },
    "papermill": {
     "duration": 24108.028654,
     "end_time": "2024-09-01T14:20:45.803908",
     "exception": false,
     "start_time": "2024-09-01T07:38:57.775254",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 0.6292\n",
      "Epoch [2/100], Loss: 0.5309\n",
      "Epoch [3/100], Loss: 0.4560\n",
      "Epoch [4/100], Loss: 0.3891\n",
      "Epoch [5/100], Loss: 0.3427\n",
      "Epoch [6/100], Loss: 0.3091\n",
      "Epoch [7/100], Loss: 0.2832\n",
      "Epoch [8/100], Loss: 0.2631\n",
      "Epoch [9/100], Loss: 0.2465\n",
      "Epoch [10/100], Loss: 0.2313\n",
      "Epoch [11/100], Loss: 0.2178\n",
      "Epoch [12/100], Loss: 0.2056\n",
      "Epoch [13/100], Loss: 0.1950\n",
      "Epoch [14/100], Loss: 0.1867\n",
      "Epoch [15/100], Loss: 0.1768\n",
      "Epoch [16/100], Loss: 0.1692\n",
      "Epoch [17/100], Loss: 0.1608\n",
      "Epoch [18/100], Loss: 0.1566\n",
      "Epoch [19/100], Loss: 0.1479\n",
      "Epoch [20/100], Loss: 0.1432\n",
      "Epoch [21/100], Loss: 0.1374\n",
      "Epoch [22/100], Loss: 0.1340\n",
      "Epoch [23/100], Loss: 0.1276\n",
      "Epoch [24/100], Loss: 0.1239\n",
      "Epoch [25/100], Loss: 0.1211\n",
      "Epoch [26/100], Loss: 0.1191\n",
      "Epoch [27/100], Loss: 0.1147\n",
      "Epoch [28/100], Loss: 0.1136\n",
      "Epoch [29/100], Loss: 0.1098\n",
      "Epoch [30/100], Loss: 0.1085\n",
      "Epoch [31/100], Loss: 0.1058\n",
      "Epoch [32/100], Loss: 0.1030\n",
      "Epoch [33/100], Loss: 0.1016\n",
      "Epoch [34/100], Loss: 0.1006\n",
      "Epoch [35/100], Loss: 0.0976\n",
      "Epoch [36/100], Loss: 0.0978\n",
      "Epoch [37/100], Loss: 0.0976\n",
      "Epoch [38/100], Loss: 0.0947\n",
      "Epoch [39/100], Loss: 0.0933\n",
      "Epoch [40/100], Loss: 0.0926\n",
      "Epoch [41/100], Loss: 0.0909\n",
      "Epoch [42/100], Loss: 0.0902\n",
      "Epoch [43/100], Loss: 0.0909\n",
      "Epoch [44/100], Loss: 0.0893\n",
      "Epoch [45/100], Loss: 0.0893\n",
      "Epoch [46/100], Loss: 0.0882\n",
      "Epoch [47/100], Loss: 0.0873\n",
      "Epoch [48/100], Loss: 0.0877\n",
      "Epoch [49/100], Loss: 0.0865\n",
      "Epoch [50/100], Loss: 0.0867\n",
      "Epoch [51/100], Loss: 0.0851\n",
      "Epoch [52/100], Loss: 0.0849\n",
      "Epoch [53/100], Loss: 0.0847\n",
      "Epoch [54/100], Loss: 0.0845\n",
      "Epoch [55/100], Loss: 0.0835\n",
      "Epoch [56/100], Loss: 0.0838\n",
      "Epoch [57/100], Loss: 0.0834\n",
      "Epoch [58/100], Loss: 0.0834\n",
      "Epoch [59/100], Loss: 0.0824\n",
      "Epoch [60/100], Loss: 0.0821\n",
      "Epoch [61/100], Loss: 0.0825\n",
      "Epoch [62/100], Loss: 0.0821\n",
      "Epoch [63/100], Loss: 0.0814\n",
      "Epoch [64/100], Loss: 0.0823\n",
      "Epoch [65/100], Loss: 0.0815\n",
      "Epoch [66/100], Loss: 0.0807\n",
      "Epoch [67/100], Loss: 0.0805\n",
      "Epoch [68/100], Loss: 0.0805\n",
      "Epoch [69/100], Loss: 0.0802\n",
      "Epoch [70/100], Loss: 0.0796\n",
      "Epoch [71/100], Loss: 0.0805\n",
      "Epoch [72/100], Loss: 0.0799\n",
      "Epoch [73/100], Loss: 0.0800\n",
      "Epoch [74/100], Loss: 0.0792\n",
      "Epoch [75/100], Loss: 0.0804\n",
      "Epoch [76/100], Loss: 0.0787\n",
      "Epoch [77/100], Loss: 0.0793\n",
      "Epoch [78/100], Loss: 0.0786\n",
      "Epoch [79/100], Loss: 0.0788\n",
      "Epoch [80/100], Loss: 0.0792\n",
      "Epoch [81/100], Loss: 0.0791\n",
      "Epoch [82/100], Loss: 0.0786\n",
      "Epoch [83/100], Loss: 0.0786\n",
      "Epoch [84/100], Loss: 0.0792\n",
      "Epoch [85/100], Loss: 0.0787\n",
      "Epoch [86/100], Loss: 0.0784\n",
      "Epoch [87/100], Loss: 0.0777\n",
      "Epoch [88/100], Loss: 0.0781\n",
      "Epoch [89/100], Loss: 0.0773\n",
      "Epoch [90/100], Loss: 0.0776\n",
      "Epoch [91/100], Loss: 0.0780\n",
      "Epoch [92/100], Loss: 0.0768\n",
      "Epoch [93/100], Loss: 0.0782\n",
      "Epoch [94/100], Loss: 0.0778\n",
      "Epoch [95/100], Loss: 0.0771\n",
      "Epoch [96/100], Loss: 0.0772\n",
      "Epoch [97/100], Loss: 0.0772\n",
      "Epoch [98/100], Loss: 0.0768\n",
      "Epoch [99/100], Loss: 0.0763\n",
      "Epoch [100/100], Loss: 0.0776\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "input_shape = 100\n",
    "hidden_shape = 200\n",
    "output_shape = 1\n",
    "num_layers = 4\n",
    "nepochs = 100\n",
    "dropoput = 0.1\n",
    "learning_rate = 0.0001\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(LSTM, self).__init__()\n",
    "\n",
    "    # self.L1 = nn.Linear(input_shape, 15)\n",
    "    # self.L2 = nn.Linear(15, 20)\n",
    "    # self.L3 = nn.Linear(20, 20)\n",
    "    self.LSTM = nn.LSTM(input_shape, hidden_shape, num_layers = num_layers, batch_first=True, dropout=dropoput)\n",
    "\n",
    "    # batch size, sequence length, no. of feature (100)\n",
    "\n",
    "    self.out1 = nn.Linear(hidden_shape, 100)\n",
    "    self.out2 = nn.Linear(100, 10)\n",
    "    self.out3 = nn.Linear(10, output_shape)\n",
    "    \n",
    "    self.dropout = nn.Dropout(dropoput)\n",
    "\n",
    "    self.relu = nn.ReLU()\n",
    "\n",
    "  def forward(self, x, lengths):\n",
    "    packed_input = rnn_utils.pack_padded_sequence(x, lengths, batch_first=True, enforce_sorted=False)\n",
    "    packed_output, _ = self.LSTM(packed_input)\n",
    "    output, _ = rnn_utils.pad_packed_sequence(packed_output, batch_first=True)\n",
    "    \n",
    "#     print(\"output\", output.size())\n",
    "\n",
    "    x = output[:, -1, :]\n",
    "    \n",
    "#     print(\"output\", output.size())\n",
    "\n",
    "    x = self.relu(x)\n",
    "    x = self.dropout(self.relu(self.out1(x)))\n",
    "    x = self.dropout(self.relu(self.out2(x)))\n",
    "    x = self.out3(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "model = LSTM().to(device)\n",
    "\n",
    "# model.load_state_dict(torch.load('/kaggle/input/emaillstm/pytorch/default/1/modelCombined1.pth'))\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "# criterion = nn.MSELoss()\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
    "\n",
    "for epoch in range(nepochs):\n",
    "#   l = 0\n",
    "  running_loss = 0.0\n",
    "  for data, label in train_dataset:\n",
    "#     print(TrainLengths[l])\n",
    "    data = data.to(device)\n",
    "#     print(calLenghts(data))\n",
    "    output = model(data, calLenghts(data))\n",
    "    label = label.to(device)\n",
    "    loss = criterion(output, label)\n",
    "    \n",
    "    running_loss += loss.item()\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "#     l += 1\n",
    "\n",
    "  print(f'Epoch [{epoch+1}/{nepochs}], Loss: {running_loss / len(train_dataset):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "351ea2f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-01T14:20:45.832464Z",
     "iopub.status.busy": "2024-09-01T14:20:45.832032Z",
     "iopub.status.idle": "2024-09-01T14:22:30.033148Z",
     "shell.execute_reply": "2024-09-01T14:22:30.032223Z"
    },
    "papermill": {
     "duration": 104.232291,
     "end_time": "2024-09-01T14:22:30.049737",
     "exception": false,
     "start_time": "2024-09-01T14:20:45.817446",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy of the network: 95.64 %\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    ncorrected = 0\n",
    "    # n = len(test_loader.dataset)\n",
    "    n = 0\n",
    "\n",
    "    for data, label in train_dataset:\n",
    "        data = data.to(device)\n",
    "        label = label.reshape(-1, 1).to(device)\n",
    "        output = model(data, calLenghts(data))\n",
    "        output = torch.sigmoid(output)\n",
    "        # Apply a threshold to the output to get the predicted class\n",
    "        predicted = (output >= 0.5).float()  # Convert probabilities to 0 or 1\n",
    "\n",
    "        ncorrected += (predicted == label).sum().item()\n",
    "        n += label.size(0)\n",
    "\n",
    "    acc = ncorrected / n\n",
    "\n",
    "    print(f'Train Accuracy of the network: {100 * acc:.2f} %')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7fbb693c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-01T14:22:30.078261Z",
     "iopub.status.busy": "2024-09-01T14:22:30.077953Z",
     "iopub.status.idle": "2024-09-01T14:22:30.925923Z",
     "shell.execute_reply": "2024-09-01T14:22:30.924980Z"
    },
    "papermill": {
     "duration": 0.864892,
     "end_time": "2024-09-01T14:22:30.928154",
     "exception": false,
     "start_time": "2024-09-01T14:22:30.063262",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the network: 91.51 %\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    ncorrected = 0\n",
    "    # n = len(test_loader.dataset)\n",
    "    n = 0\n",
    "\n",
    "    for data, label in test_dataset:\n",
    "        data = data.to(device)\n",
    "        label = label.reshape(-1, 1).to(device)\n",
    "        output = model(data, calLenghts(data))\n",
    "        output = torch.sigmoid(output)\n",
    "        # Apply a threshold to the output to get the predicted class\n",
    "        predicted = (output >= 0.5).float()  # Convert probabilities to 0 or 1\n",
    "\n",
    "        ncorrected += (predicted == label).sum().item()\n",
    "        n += label.size(0)\n",
    "\n",
    "    acc = ncorrected / n\n",
    "\n",
    "    print(f'Test Accuracy of the network: {100 * acc:.2f} %')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d91b379f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-01T14:22:30.957432Z",
     "iopub.status.busy": "2024-09-01T14:22:30.957139Z",
     "iopub.status.idle": "2024-09-01T14:22:30.971626Z",
     "shell.execute_reply": "2024-09-01T14:22:30.970837Z"
    },
    "papermill": {
     "duration": 0.031431,
     "end_time": "2024-09-01T14:22:30.973589",
     "exception": false,
     "start_time": "2024-09-01T14:22:30.942158",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"modelCombined1_nlayer4_hidden_200batch16dropout02.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde9b7ec",
   "metadata": {
    "papermill": {
     "duration": 0.013543,
     "end_time": "2024-09-01T14:22:31.000817",
     "exception": false,
     "start_time": "2024-09-01T14:22:30.987274",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 5570083,
     "sourceId": 9211718,
     "sourceType": "datasetVersion"
    },
    {
     "modelId": 108979,
     "modelInstanceId": 84745,
     "sourceId": 101055,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30746,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 24309.519179,
   "end_time": "2024-09-01T14:22:34.690970",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-09-01T07:37:25.171791",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
