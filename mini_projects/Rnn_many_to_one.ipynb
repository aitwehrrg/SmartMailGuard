{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "## many to one RNN\n",
    "\n",
    "class RNN:\n",
    "\n",
    "  def __init__(self, layerDim, activations, a0):\n",
    "    self.a0 = a0\n",
    "    self.acacheNN = []\n",
    "    self.zcacheNN = []\n",
    "    self.acacheRNN = []\n",
    "    self.zcacheRNN = []\n",
    "\n",
    "    self.layerDim = layerDim\n",
    "    self.layers = len(layerDim)\n",
    "    self.activations = activations\n",
    "    self.t = 0\n",
    "\n",
    "    self.W = []\n",
    "    self.b = []\n",
    "    self.dW = []\n",
    "    self.db = []\n",
    "\n",
    "    self.init_weights()\n",
    "\n",
    "  def init_weights(self):\n",
    "    self.W = []\n",
    "    self.b = []\n",
    "    for i in range(2, self.layers-1):\n",
    "      # print(i)\n",
    "      # print(self.layerDim[i])\n",
    "      # print(self.layerDim[i-1])\n",
    "      self.W.append(np.random.randn(self.layerDim[i], self.layerDim[i-1]) * np.sqrt(2/self.layerDim[i-1]))\n",
    "      self.b.append(np.zeros((self.layerDim[i], 1)))\n",
    "\n",
    "      self.dW.append(np.zeros((self.layerDim[i], self.layerDim[i-1])))\n",
    "      self.db.append(np.zeros((self.layerDim[i], 1)))\n",
    "\n",
    "    self.Wx = np.random.randn(self.layerDim[1], self.layerDim[0]) * np.sqrt(2/self.layerDim[0])\n",
    "    self.Wa = np.random.randn(self.layerDim[1], self.layerDim[-2]) * np.sqrt(2/self.layerDim[1])\n",
    "    self.ba = np.zeros((self.layerDim[1], 1))\n",
    "\n",
    "    self.dWx = np.zeros((self.layerDim[1], self.layerDim[0]))\n",
    "    self.dWa = np.zeros((self.layerDim[1], self.layerDim[-2]))\n",
    "    self.dba = np.zeros((self.layerDim[1], 1))\n",
    "\n",
    "    self.Wy = np.random.randn(self.layerDim[-1], self.layerDim[-2]) * np.sqrt(2/self.layerDim[-2])\n",
    "    self.by = np.zeros((self.layerDim[-1], 1))\n",
    "\n",
    "    self.dWy = np.zeros((self.layerDim[-1], self.layerDim[-2]))\n",
    "    self.dby = np.zeros((self.layerDim[-1], 1))\n",
    "\n",
    "\n",
    "  def sigmoid (self, Z):\n",
    "    Z = np.clip(Z, -500, 500) \n",
    "    return 1/(1+np.exp(-Z))\n",
    "  \n",
    "  def relu (self, Z):\n",
    "    return np.maximum(0, Z)\n",
    "  \n",
    "  def tanh (self, Z):\n",
    "    return np.tanh(Z)\n",
    "  \n",
    "  def softmax (self, Z):\n",
    "    expZ = np.exp(Z - np.max(Z))\n",
    "    return expZ / expZ.sum(axis=0, keepdims=True)\n",
    "  \n",
    "  def activationsfunc (self, Z, activation):\n",
    "    if activation == 'sigmoid':\n",
    "      return self.sigmoid(Z)\n",
    "    elif activation == 'relu':\n",
    "      return self.relu(Z)\n",
    "    elif activation == 'tanh':\n",
    "      return self.tanh(Z)\n",
    "    else:\n",
    "      return Z\n",
    "    \n",
    "  def activationsDerivative(self, Z, activation):\n",
    "    if activation == 'sigmoid':\n",
    "      sig = self.sigmoid(Z)\n",
    "      return sig * (1 - sig)\n",
    "    elif activation == 'relu':\n",
    "      return (Z > 0).astype(Z.dtype)\n",
    "    elif activation == 'tanh':\n",
    "      return 1 - np.power(self.tanh(Z), 2)\n",
    "    else:\n",
    "      return 1\n",
    "    \n",
    "  def singleForwardNN(self, a_prev, w, b, activation):\n",
    "    z = w @ a_prev + b\n",
    "    a = self.activationsfunc(z, activation)\n",
    "\n",
    "    self.acacheNN[self.t].append(a)\n",
    "    self.zcacheNN[self.t].append(z)\n",
    "\n",
    "    return a\n",
    "  \n",
    "  def forwardNN(self, X):\n",
    "    self.acacheNN.append([X])\n",
    "    self.zcacheNN.append([])\n",
    "\n",
    "    a = X\n",
    "    for i in range(len(self.W)):\n",
    "      a = self.singleForwardNN(a, self.W[i], self.b[i], self.activations[i+1])\n",
    "\n",
    "    return a\n",
    "  \n",
    "  def singleForwardRNN(self, a_prev, x, activation):\n",
    "    # print(x.shape)\n",
    "    # print(a_prev.shape)\n",
    "    # print(self.Wx.shape)\n",
    "    # print(self.Wa.shape)\n",
    "    # print(self.ba.shape)\n",
    "    z = self.Wx @ x + self.Wa @ a_prev + self.ba\n",
    "    a = self.activationsfunc(z, activation)\n",
    "\n",
    "    self.acacheRNN.append(a)\n",
    "    self.zcacheRNN.append(z)\n",
    "\n",
    "    a = self.forwardNN(a)\n",
    "\n",
    "    return a\n",
    "  \n",
    "  def forwardRNN(self, X):\n",
    "    a = self.a0\n",
    "    self.acacheRNN = [a]\n",
    "    self.zcacheRNN = []\n",
    "    self.acacheNN = []\n",
    "    self.zcacheNN = []\n",
    "    self.t = 0\n",
    "\n",
    "    for i in range(X.shape[1]):\n",
    "      a = self.singleForwardRNN(a, X[:, i:i+1], self.activations[0])\n",
    "      self.t += 1\n",
    "    \n",
    "    return a\n",
    "  \n",
    "  def singleBackwardNN(self, da, w, b, z, a_prev, activation):\n",
    "    dz = da * self.activationsDerivative(z, activation)\n",
    "    dw = dz @ a_prev.T\n",
    "    db = np.sum(dz, axis=1, keepdims=True)\n",
    "    da_prev = w.T @ dz\n",
    "\n",
    "    return da_prev, dw, db\n",
    "  \n",
    "  def backwardNN(self, da):\n",
    "\n",
    "    for i in range(len(self.W)-1, -1, -1):\n",
    "      da, dw, db = self.singleBackwardNN(da, self.W[i], self.b[i], self.zcacheNN[self.t][i], self.acacheNN[self.t][i], self.activations[i+1])\n",
    "      self.dW[i] += dw\n",
    "      self.db[i] += db\n",
    "\n",
    "    return da\n",
    "  \n",
    "  def singleBackwardRNN(self, da,z, x, a_prev, activation):\n",
    "    da = self.backwardNN(da)\n",
    "\n",
    "    dz = da * self.activationsDerivative(z, activation)\n",
    "    self.dWx += dz @ x.T\n",
    "    self.dWa += dz @ a_prev.T\n",
    "    self.dba += np.sum(dz, axis=1, keepdims=True)\n",
    "\n",
    "    da_prev = self.Wa.T @ dz\n",
    "\n",
    "    return da_prev\n",
    "  \n",
    "  def backwardRNN(self, lossDerivative, X):\n",
    "    dz = lossDerivative\n",
    "    # print(dz.shape)\n",
    "    # print(self.acacheRNN[-1].shape)\n",
    "    # print(self.dWy.shape)\n",
    "    self.dWy += dz @ self.acacheNN[-1][-1].T\n",
    "    self.dby += np.sum(dz, axis=1, keepdims=True)\n",
    "    da = self.Wy.T @ dz\n",
    "\n",
    "\n",
    "    for i in range(X.shape[1]-1, -1, -1):\n",
    "      self.t -= 1\n",
    "      da = self.singleBackwardRNN(da, self.zcacheRNN[i], X[:, i:i+1], self.acacheNN[self.t][-1], self.activations[0])\n",
    "\n",
    "    return da\n",
    "  \n",
    "  def updateWeights(self, learning_rate):\n",
    "    for i in range(len(self.W)):\n",
    "      self.W[i] -= learning_rate * self.dW[i]\n",
    "      self.b[i] -= learning_rate * self.db[i]\n",
    "\n",
    "      self.dW[i] = np.zeros(self.dW[i].shape)\n",
    "      self.db[i] = np.zeros(self.db[i].shape)\n",
    "      \n",
    "    self.Wx -= learning_rate * self.dWx\n",
    "    self.Wa -= learning_rate * self.dWa\n",
    "    self.ba -= learning_rate * self.dba\n",
    "\n",
    "    self.Wy -= learning_rate * self.dWy\n",
    "    self.by -= learning_rate * self.dby\n",
    "\n",
    "    self.dWx = np.zeros(self.dWx.shape)\n",
    "    self.dWa = np.zeros(self.dWa.shape)\n",
    "    self.dba = np.zeros(self.dba.shape)\n",
    "    self.dWy = np.zeros(self.dWy.shape)\n",
    "    self.dby = np.zeros(self.dby.shape)\n",
    "    self.dWx = np.zeros(self.dWx.shape)\n",
    "\n",
    "  \n",
    "  def predict(self, X):\n",
    "    a = self.forwardRNN(X)\n",
    "    y = self.Wy @ a + self.by\n",
    "    y = self.softmax(y)\n",
    "\n",
    "    return y.reshape(-1, 1)\n",
    "  \n",
    "  def loss(self, y, y_hat):\n",
    "    y = np.clip(y, 1e-10, 1-1e-10)\n",
    "    y_hat = np.clip(y_hat, 1e-10, 1-1e-10)\n",
    "\n",
    "    return -np.sum(y * np.log(y_hat))\n",
    "  \n",
    "  def lossDerivativeSoftmax(self, y, y_hat):\n",
    "    return  y_hat - y\n",
    "  \n",
    "  def train(self, X, Y, learning_rate, epochs):\n",
    "    examples = len(X)\n",
    "\n",
    "    for i in range(epochs):\n",
    "      loss = 0\n",
    "      for j in range(examples):\n",
    "        y_hat = self.predict(X[j])\n",
    "        loss += self.loss(Y[0,j:j+1], y_hat)\n",
    "        lossDerivative = self.lossDerivativeSoftmax(Y[0,j:j+1], y_hat)\n",
    "        self.backwardRNN(lossDerivative, X[j])\n",
    "      self.updateWeights(learning_rate)\n",
    "      \n",
    "      if i % 100 == 0:\n",
    "        print(\"Epoch: \", i, \" Loss: \", loss)\n",
    "      \n",
    "      # print(\"Epoch: \", i, \" Loss: \", loss)\n",
    "\n",
    "  def accuracy (self, X, Y):\n",
    "    # A = self.predict(X)\n",
    "    A = np.zeros(Y.shape)\n",
    "    for i in range(Y.shape[1]):\n",
    "      A[:, i:i+1] = self.predict(X[i])\n",
    "    return np.mean(np.argmax(Y, axis=0) == np.argmax(A, axis=0))\n",
    "\n",
    "  def precision (self, X, Y):\n",
    "    A = np.zeros(Y.shape)\n",
    "    for i in range(Y.shape[1]):\n",
    "      A[:, i:i+1] = self.predict(X[i])\n",
    "\n",
    "    A = (A == A.max(axis=0, keepdims=1)).astype(int)\n",
    "    true_positive = np.sum((Y == 1) & (A == 1))\n",
    "    predicted_positive = np.sum(A == 1)\n",
    "    return true_positive / predicted_positive if predicted_positive > 0 else 0\n",
    "    \n",
    "  def saveWeights(self, filename):\n",
    "    np.savez(filename, W=self.W, b=self.b, Wx=self.Wx, Wa=self.Wa, ba=self.ba, Wy=self.Wy, by=self.by)\n",
    "\n",
    "  def loadWeights(self, filename):\n",
    "    data = np.load(filename)\n",
    "    self.W = data['W']\n",
    "    self.b = data['b']\n",
    "    self.Wx = data['Wx']\n",
    "    self.Wa = data['Wa']\n",
    "    self.ba = data['ba']\n",
    "    self.Wy = data['Wy']\n",
    "    self.by = data['by']\n",
    "\n",
    "  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define a function to load GloVe vectors\n",
    "def load_glove_vectors(filepath):\n",
    "    word_to_vec = {}\n",
    "    with open(filepath, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            vector = np.asarray(values[1:], dtype='float32')\n",
    "            word_to_vec[word] = vector\n",
    "\n",
    "    word_to_vec['<eol>'] = np.zeros((100,))\n",
    "    word_to_vec['<unk>'] = np.zeros((100,))\n",
    "    return word_to_vec\n",
    "\n",
    "# Load the vectors\n",
    "glove_vectors = load_glove_vectors('Data/glove.6B/glove.6B.100d.txt')\n",
    "\n",
    "# glove_vectors[\"don't\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[what, a, great, day, !, looks, like, dream]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[i, feel, sorry, ,, i, miss, you, here, in, th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[dont, angry, me]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[we, attend, in, the, class, just, for, listen...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[those, who, want, to, go, ,, let, them, go]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>[sorry, ,, well, try, to, keep, it, down]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>[according, to, ,, a, quarter, of, families, u...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>[the, plan, to, not, spend, money, is, not, go...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>[congratulations, !, you, guys, finish, a, mon...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>[actually, ,, i, wish, i, was, back, in, tahoe...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Text  Sentiment\n",
       "0         [what, a, great, day, !, looks, like, dream]          1\n",
       "1    [i, feel, sorry, ,, i, miss, you, here, in, th...          1\n",
       "2                                    [dont, angry, me]          0\n",
       "3    [we, attend, in, the, class, just, for, listen...          0\n",
       "4         [those, who, want, to, go, ,, let, them, go]          0\n",
       "..                                                 ...        ...\n",
       "492          [sorry, ,, well, try, to, keep, it, down]          0\n",
       "494  [according, to, ,, a, quarter, of, families, u...          0\n",
       "495  [the, plan, to, not, spend, money, is, not, go...          0\n",
       "497  [congratulations, !, you, guys, finish, a, mon...          1\n",
       "498  [actually, ,, i, wish, i, was, back, in, tahoe...          0\n",
       "\n",
       "[300 rows x 2 columns]"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def remove_punctuation_without_spaces(text):\n",
    "    return re.sub(r'(?<!\\s)([^\\w\\s])(?!\\s)', '', str(text).strip())\n",
    "\n",
    "def Seperate_punctuation(text):\n",
    "    return re.sub(r'([^\\w\\s])', r' \\1 ', str(text).strip())\n",
    "\n",
    "def remove_extra_spaces(text):\n",
    "    return re.sub(' +', ' ', text)\n",
    "\n",
    "df = pd.read_csv('Data/sentiment-analysis2.csv')\n",
    "# df['Text'] = df['Message'] if not NaN else df['Subject']\n",
    "\n",
    "# df['Text'] = df['Message'].fillna(df['Subject'])\n",
    "df = df.rename(columns={'text': 'Text', 'sentiment': 'Sentiment'})\n",
    "\n",
    "df = df.drop(columns=['Year', 'Month', 'Day', 'Time of Tweet', 'Platform'], axis=1)\n",
    "\n",
    "df[\"Text\"] = df[\"Text\"].apply(remove_punctuation_without_spaces)\n",
    "df[\"Text\"] = df[\"Text\"].apply(Seperate_punctuation)\n",
    "df[\"Text\"] = df[\"Text\"].str.replace('\\n', ' ')\n",
    "df[\"Text\"] = df[\"Text\"].apply(remove_extra_spaces)\n",
    "df[\"Text\"] = df[\"Text\"].str.strip()\n",
    "df[\"Text\"] = df[\"Text\"].str.lower()\n",
    "df[\"Text\"] = df[\"Text\"].str.split(' ')\n",
    "\n",
    "# df[\"Spam\"] = df[\"Spam/Ham\"].map({'spam': 1, 'ham': 0})\n",
    "\n",
    "df = df[df[\"Sentiment\"] != 'neutral']\n",
    "df['Sentiment'] = df['Sentiment'].map({'positive': 1, 'negative': 0})\n",
    "\n",
    "# df = df.drop('Spam/Ham', axis=1)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import re\n",
    "\n",
    "# def remove_punctuation(text):\n",
    "#     return re.sub(r'[^\\w\\s]', '', str(text).strip())\n",
    "\n",
    "# def remove_extra_spaces(text):\n",
    "#     return re.sub(' +', ' ', text)\n",
    "\n",
    "# df = pd.read_csv('Data/sentiment-analysis.csv', delimiter=', ', engine='python')\n",
    "# # df['Text'] = df['Message'] if not NaN else df['Subject']\n",
    "\n",
    "# # df['Text'] = df['Message'].fillna(df['Subject'])\n",
    "\n",
    "# df = df.drop(columns=['Source', 'Date/Time', 'User ID', 'Location', 'Confidence Score'], axis=1)\n",
    "\n",
    "# df[\"Text\"] = df[\"Text\"].apply(remove_punctuation)\n",
    "# df[\"Text\"] = df[\"Text\"].str.replace('\\n', ' ')\n",
    "# df[\"Text\"] = df[\"Text\"].apply(remove_extra_spaces)\n",
    "# df[\"Text\"] = df[\"Text\"].str.strip()\n",
    "# df[\"Text\"] = df[\"Text\"].str.lower()\n",
    "# df[\"Text\"] = df[\"Text\"].str.split(' ')\n",
    "\n",
    "# # df[\"Spam\"] = df[\"Spam/Ham\"].map({'spam': 1, 'ham': 0})\n",
    "\n",
    "# df['Sentiment'] = df['Sentiment'].map({'Positive': 1, 'Negative': 0})\n",
    "\n",
    "# # df = df.drop('Spam/Ham', axis=1)\n",
    "\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import re\n",
    "\n",
    "# def remove_punctuation(text):\n",
    "#     return re.sub(r'[^\\w\\s]', '', str(text).strip())\n",
    "\n",
    "# def remove_extra_spaces(text):\n",
    "#     return re.sub(' +', ' ', text)\n",
    "\n",
    "# df = pd.read_csv('Data/enron_spam_data/enron_spam_data.csv')\n",
    "# # df['Text'] = df['Message'] if not NaN else df['Subject']\n",
    "\n",
    "# df['Text'] = df['Message'].fillna(df['Subject'])\n",
    "\n",
    "# df = df.drop(columns=['Message', 'Subject', 'Message ID', 'Date'], axis=1)\n",
    "\n",
    "# df[\"Text\"] = df[\"Text\"].apply(remove_punctuation)\n",
    "# df[\"Text\"] = df[\"Text\"].str.replace('\\n', ' ')\n",
    "# df[\"Text\"] = df[\"Text\"].apply(remove_extra_spaces)\n",
    "# df[\"Text\"] = df[\"Text\"].str.strip()\n",
    "# df[\"Text\"] = df[\"Text\"].str.lower()\n",
    "# df[\"Text\"] = df[\"Text\"].str.split(' ')\n",
    "\n",
    "# df[\"Spam\"] = df[\"Spam/Ham\"].map({'spam': 1, 'ham': 0})\n",
    "\n",
    "# df = df.drop('Spam/Ham', axis=1)\n",
    "\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import re\n",
    "\n",
    "# def remove_punctuation(text):\n",
    "#     return re.sub(r'[^\\w\\s]', '', str(text).strip())\n",
    "\n",
    "# def remove_extra_spaces(text):\n",
    "#     return re.sub(' +', ' ', text)\n",
    "\n",
    "# df = pd.read_csv('Data/spam_or_not_spam/spam_or_not_spam.csv')\n",
    "# # df['Text'] = df['Message'] if not NaN else df['Subject']\n",
    "\n",
    "# # df['Text'] = df['Message'].fillna(df['Subject'])\n",
    "\n",
    "# # df = df.drop(columns=['Message', 'Subject', 'Message ID', 'Date'], axis=1)\n",
    "\n",
    "# df[\"Text\"] = df[\"email\"].apply(remove_punctuation)\n",
    "# df[\"Text\"] = df[\"Text\"].str.replace('\\n', ' ')\n",
    "# df[\"Text\"] = df[\"Text\"].apply(remove_extra_spaces)\n",
    "# df[\"Text\"] = df[\"Text\"].str.strip()\n",
    "# df[\"Text\"] = df[\"Text\"].str.lower()\n",
    "# df[\"Text\"] = df[\"Text\"].str.split(' ')\n",
    "\n",
    "# df = df.drop(columns=['email'], axis=1)\n",
    "\n",
    "# df['Spam'] = df['label']\n",
    "# # df[\"Spam/Ham\"] = df[\"Spam/Ham\"].map({'spam': 1, 'ham': 0})\n",
    "\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['Text'].values\n",
    "Y = df['Sentiment'].values\n",
    "\n",
    "X_vec = []\n",
    "Y_vec = np.zeros((2, len(Y)))\n",
    "\n",
    "for i in range(len(X)):\n",
    "  vec = np.zeros((100, len(X[i])))\n",
    "  for j in range(len(X[i])):\n",
    "    if X[i][j] in glove_vectors:\n",
    "      vec[:, j] = glove_vectors[X[i][j]]\n",
    "    else:\n",
    "      vec[:, j] = glove_vectors['<unk>']\n",
    "\n",
    "  X_vec.append(vec)\n",
    "  Y_vec[Y[i] - 1, i] = 1\n",
    "\n",
    "random = np.random.permutation(len(X_vec))\n",
    "theshold = int(0.8*len(random))\n",
    "X_train = [X_vec[i] for i in random[0:theshold]]\n",
    "Y_train = Y_vec[:, random[0:theshold]]\n",
    "\n",
    "X_test = [X_vec[i] for i in random[theshold:]]\n",
    "Y_test = Y_vec[:, random[theshold:]]\n",
    "# print(X_vec[0])\n",
    "# print(Y_vec[:, 0:1])\n",
    "# Y_vec[:, 0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0  Loss:  227.8952549130674\n",
      "Epoch:  100  Loss:  197.31535767483368\n",
      "Epoch:  200  Loss:  194.16832395510264\n",
      "Epoch:  300  Loss:  193.72044966438474\n",
      "Epoch:  400  Loss:  196.14906346595387\n",
      "Epoch:  500  Loss:  187.26997140775552\n",
      "Epoch:  600  Loss:  438.8531007739544\n",
      "Epoch:  700  Loss:  3069.749655882449\n",
      "Epoch:  800  Loss:  3085.4640245609376\n",
      "Epoch:  900  Loss:  233.29878279745836\n",
      "Epoch:  1000  Loss:  3085.4640245609376\n",
      "Epoch:  1100  Loss:  215.44468057443706\n",
      "Epoch:  1200  Loss:  189.13560670289573\n",
      "Epoch:  1300  Loss:  187.00371876854055\n",
      "Epoch:  1400  Loss:  186.69129258021397\n",
      "Epoch:  1500  Loss:  186.5820848108147\n",
      "Epoch:  1600  Loss:  186.5044142684774\n",
      "Epoch:  1700  Loss:  186.4297129187466\n",
      "Epoch:  1800  Loss:  186.35553073889272\n",
      "Epoch:  1900  Loss:  186.28378661901604\n",
      "Epoch:  2000  Loss:  186.21594103279034\n",
      "Epoch:  2100  Loss:  186.14803019470267\n",
      "Epoch:  2200  Loss:  186.08466646616571\n",
      "Epoch:  2300  Loss:  186.02674780513726\n",
      "Epoch:  2400  Loss:  185.97484544395422\n",
      "Epoch:  2500  Loss:  185.92930411148893\n",
      "Epoch:  2600  Loss:  185.89024785069765\n",
      "Epoch:  2700  Loss:  185.85759120780938\n",
      "Epoch:  2800  Loss:  186.59254407469186\n",
      "Epoch:  2900  Loss:  186.47444685570798\n"
     ]
    }
   ],
   "source": [
    "model = RNN([100, 100,100,75, 50, 2], ['tanh', 'relu','relu','relu', 'softmax'], np.zeros((50, 1)))\n",
    "\n",
    "model.train(X_train, Y_train, 0.00001, 3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.5583333333333333\n",
      "Test accuracy: 0.5333333333333333\n",
      "Train precision: 0.5583333333333333\n",
      "Test precision: 0.5333333333333333\n"
     ]
    }
   ],
   "source": [
    "print(\"Train accuracy:\", model.accuracy(X_train, Y_train))\n",
    "print(\"Test accuracy:\", model.accuracy(X_test, Y_test))\n",
    "\n",
    "print(\"Train precision:\", model.precision(X_train, Y_train))\n",
    "print(\"Test precision:\", model.precision(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.53275042]\n",
      " [0.46724958]]\n",
      "[[1.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "print(model.predict(X_train[1]))\n",
    "print(Y_train[:, 0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (3,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[197], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msaveWeights\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodel.npz\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[187], line 257\u001b[0m, in \u001b[0;36mRNN.saveWeights\u001b[1;34m(self, filename)\u001b[0m\n\u001b[0;32m    256\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msaveWeights\u001b[39m(\u001b[38;5;28mself\u001b[39m, filename):\n\u001b[1;32m--> 257\u001b[0m   \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msavez\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mW\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mWx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mWx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mWa\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mWa\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mba\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mba\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mWy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mWy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mby\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mby\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\numpy\\lib\\npyio.py:639\u001b[0m, in \u001b[0;36msavez\u001b[1;34m(file, *args, **kwds)\u001b[0m\n\u001b[0;32m    555\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_savez_dispatcher)\n\u001b[0;32m    556\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msavez\u001b[39m(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds):\n\u001b[0;32m    557\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Save several arrays into a single file in uncompressed ``.npz`` format.\u001b[39;00m\n\u001b[0;32m    558\u001b[0m \n\u001b[0;32m    559\u001b[0m \u001b[38;5;124;03m    Provide arrays as keyword arguments to store them under the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    637\u001b[0m \n\u001b[0;32m    638\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 639\u001b[0m     \u001b[43m_savez\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\numpy\\lib\\npyio.py:740\u001b[0m, in \u001b[0;36m_savez\u001b[1;34m(file, args, kwds, compress, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[0;32m    738\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, val \u001b[38;5;129;01min\u001b[39;00m namedict\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m    739\u001b[0m     fname \u001b[38;5;241m=\u001b[39m key \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.npy\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 740\u001b[0m     val \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masanyarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    741\u001b[0m     \u001b[38;5;66;03m# always force zip64, gh-10776\u001b[39;00m\n\u001b[0;32m    742\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m zipf\u001b[38;5;241m.\u001b[39mopen(fname, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m, force_zip64\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m fid:\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (3,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "model.saveWeights('model.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = RNN([100, 50, 2], ['tanh', 'softmax'], np.zeros((50, 1)))\n",
    "new_model.loadWeights('model.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.5666666666666667\n",
      "Test accuracy: 0.5\n",
      "Train precision: 0.5666666666666667\n",
      "Test precision: 0.5\n"
     ]
    }
   ],
   "source": [
    "print(\"Train accuracy:\", model.accuracy(X_train, Y_train))\n",
    "print(\"Test accuracy:\", model.accuracy(X_test, Y_test))\n",
    "\n",
    "print(\"Train precision:\", model.precision(X_train, Y_train))\n",
    "print(\"Test precision:\", model.precision(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.00000000e+00]\n",
      " [5.29902188e-62]]\n",
      "[[0.]\n",
      " [1.]]\n"
     ]
    }
   ],
   "source": [
    "print(model.predict(X_train[1]))\n",
    "print(Y_train[:, 0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 12.863333333333333)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg = 0\n",
    "for i in range(len(X)):\n",
    "  avg += len(X[i])\n",
    "\n",
    "avg /= len(X)\n",
    "len(X), avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (3,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[199], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msaveWeights\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodel1.npz\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[187], line 257\u001b[0m, in \u001b[0;36mRNN.saveWeights\u001b[1;34m(self, filename)\u001b[0m\n\u001b[0;32m    256\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msaveWeights\u001b[39m(\u001b[38;5;28mself\u001b[39m, filename):\n\u001b[1;32m--> 257\u001b[0m   \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msavez\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mW\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mWx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mWx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mWa\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mWa\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mba\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mba\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mWy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mWy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mby\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mby\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\numpy\\lib\\npyio.py:639\u001b[0m, in \u001b[0;36msavez\u001b[1;34m(file, *args, **kwds)\u001b[0m\n\u001b[0;32m    555\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_savez_dispatcher)\n\u001b[0;32m    556\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msavez\u001b[39m(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds):\n\u001b[0;32m    557\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Save several arrays into a single file in uncompressed ``.npz`` format.\u001b[39;00m\n\u001b[0;32m    558\u001b[0m \n\u001b[0;32m    559\u001b[0m \u001b[38;5;124;03m    Provide arrays as keyword arguments to store them under the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    637\u001b[0m \n\u001b[0;32m    638\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 639\u001b[0m     \u001b[43m_savez\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\numpy\\lib\\npyio.py:740\u001b[0m, in \u001b[0;36m_savez\u001b[1;34m(file, args, kwds, compress, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[0;32m    738\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, val \u001b[38;5;129;01min\u001b[39;00m namedict\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m    739\u001b[0m     fname \u001b[38;5;241m=\u001b[39m key \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.npy\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 740\u001b[0m     val \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masanyarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    741\u001b[0m     \u001b[38;5;66;03m# always force zip64, gh-10776\u001b[39;00m\n\u001b[0;32m    742\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m zipf\u001b[38;5;241m.\u001b[39mopen(fname, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m, force_zip64\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m fid:\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (3,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "model.saveWeights('model1.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
